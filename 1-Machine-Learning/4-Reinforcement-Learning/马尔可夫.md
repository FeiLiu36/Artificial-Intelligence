# 马尔可夫



## 马尔可夫链

未来只取决于现在，跟过去无关

Markov Decision Process (MDP)



State $s_t$ is Markovian if and only if:
$$
p
$$




## 马尔可夫奖励过程

